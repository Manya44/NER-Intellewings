# -*- coding: utf-8 -*-
"""Copy of Untitled4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tfYi71Ggx8Xa5Bq12PaAOqf5hAevJvcr
"""

!pip install requests beautifulsoup4 spacy nltk pandas sqlalchemy flask flask-restful
!python -m spacy download en_core_web_sm
!pip install vaderSentiment

import requests
from bs4 import BeautifulSoup

def fetch_article(url):
    try:
        response = requests.get(url)
        response.raise_for_status()  # Check for HTTP request errors
        soup = BeautifulSoup(response.content, 'html.parser')
        # Extract all paragraphs to form the article text
        article_text = " ".join([p.text for p in soup.find_all('p')])
        return article_text
    except Exception as e:
        print(f"Error fetching article: {e}")
        return None

# Test the function
url = "https://timesofindia.indiatimes.com/city/bengaluru/bengaluru-techie-suicide-subhash-atuls-estranged-wife-nikita-singhania-arrested-from-gurgaon/articleshow/116330431.cms"
article_text = fetch_article(url)
print(article_text)

from google.colab import drive
drive.mount('/content/drive')

import spacy

# Load the model from the saved directory
custom_ner_model = spacy.load('/content/drive/MyDrive/custom_ner_model')

import spacy

nlp = spacy.load("/content/drive/MyDrive/custom_ner_model")

def extract_entities(text):
    if not text:
        return {"PERSON": [], "ORG": []}

    doc = nlp(text)
    entities = {"PERSON": [], "ORG": []}

    for ent in doc.ents:
        if ent.label_ == "PERSON":
            entities["PERSON"].append(ent.text)
        elif ent.label_ == "ORG":
            entities["ORG"].append(ent.text)

    # Remove duplicates
    entities["PERSON"] = list(set(entities["PERSON"]))
    entities["ORG"] = list(set(entities["ORG"]))
    return entities

# Test the function
entities = extract_entities(article_text)
print("Extracted Entities:", entities)

from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer

analyzer = SentimentIntensityAnalyzer()

def analyze_sentiment(text):
    if not text:
        return "Neutral"

    score = analyzer.polarity_scores(text)
    if score['compound'] > 0.05:
        return "Positive"
    elif score['compound'] < -0.05:
        return "Negative"
    else:
        return "Neutral"

# Test the function
sentiment = analyze_sentiment(article_text)
print("Sentiment:", sentiment)

!pip install sqlalchemy

from sqlalchemy import create_engine, Column, Integer, String, Text, JSON
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker

# Setup SQLite database
engine = create_engine('sqlite:///articles.db')
Base = declarative_base()

class Article(Base):
    __tablename__ = 'articles'
    id = Column(Integer, primary_key=True)
    url = Column(String, unique=True, nullable=False)
    text = Column(Text, nullable=False)
    entities = Column(JSON, nullable=False)
    sentiment = Column(String, nullable=False)

Base.metadata.create_all(engine)

# Create a session
Session = sessionmaker(bind=engine)
session = Session()

def save_to_database(url, text, entities, sentiment):
    article = Article(url=url, text=text, entities=entities, sentiment=sentiment)
    session.add(article)
    session.commit()
    print("Article saved successfully!")

# Test database storage
save_to_database(url, article_text, entities, sentiment)

!pip install gradio

import gradio as gr
import requests

# Gradio UI function
def process_url(url):
    article_text = fetch_article(url)
    if "Error" in article_text:
        return article_text, {}, "Error"

    entities = extract_entities(article_text)
    sentiment = analyze_sentiment(article_text)

    return article_text, entities, sentiment

# Define the Gradio interface
iface = gr.Interface(
    fn=process_url,  # The function to run
    inputs=gr.Textbox(label="Enter URL", placeholder="Enter article URL here..."),  # Input component
    outputs=[
        gr.Textbox(label="Article Text"),  # Output for article content
        gr.JSON(label="Entities (Person & Organization)"),  # Output for extracted entities
        gr.Textbox(label="Sentiment")  # Output for sentiment analysis result
    ],
    title="Article Analyzer",  # UI title
    description="Enter a URL to fetch an article and analyze its content for entities and sentiment."
)

# Launch the interface
iface.launch(share=True)  # share=True will give you a public URL for your interface