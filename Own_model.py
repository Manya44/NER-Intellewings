# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KfEkLVYmLhnjyoq_tor5DIzXSXfJbt7p
"""

!pip install spacy
!python -m spacy download en_core_web_sm

TRAINING_DATA = [
    (
        "Apple is looking at buying U.K. startup for $1 billion",
        {"entities": [(0, 5, "ORG"), (27, 30, "GPE")]}
    ),
    (
        "Elon Musk founded SpaceX in 2002.",
        {"entities": [(0, 9, "PERSON"), (18, 24, "ORG")]}
    ),
    (
        "Google announced its new AI project in London.",
        {"entities": [(0, 6, "ORG"), (39, 45, "GPE")]}
    )
]

import spacy
from spacy.training.example import Example

# Load base model
nlp = spacy.load("en_core_web_sm")

# Add a new pipeline component for NER if it doesn't exist
if "ner" not in nlp.pipe_names:
    ner = nlp.add_pipe("ner", last=True)
else:
    ner = nlp.get_pipe("ner")

# Add new labels
for _, annotations in TRAINING_DATA:
    for ent in annotations["entities"]:
        ner.add_label(ent[2])  # Add each label

!pip install spacy-lookups-data
import spacy
# Restart the kernel after installing spacy-lookups-data
# This ensures spaCy can find the newly installed tables.

import random

# Disable other pipelines to train NER only
pipe_exceptions = ["ner"]
unaffected_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]

# Start training
with nlp.disable_pipes(*unaffected_pipes):  # Only train NER
    optimizer = nlp.begin_training()
    for iteration in range(30):  # Number of training iterations
        random.shuffle(TRAINING_DATA)
        losses = {}

        for text, annotations in TRAINING_DATA:
            # Convert data into spaCy Example format
            doc = nlp.make_doc(text)
            example = Example.from_dict(doc, annotations)

            # Update the model
            nlp.update([example], drop=0.5, losses=losses)
        print(f"Iteration {iteration}, Losses: {losses}")

# Save the trained model
nlp.to_disk("custom_ner_model")

# Load the trained model
custom_nlp = spacy.load("custom_ner_model")

# Test on new text
test_text = "Jeff Bezos founded Amazon in 1994."
doc = custom_nlp(test_text)

# Print recognized entities
for ent in doc.ents:
    print(f"Entity: {ent.text}, Label: {ent.label_}")

import spacy

# Save the custom NER model to a directory
custom_nlp.to_disk('/content/custom_ner_model') # Use custom_nlp instead of custom_ner_model

from google.colab import drive
drive.mount('/content/drive')

!cp -r /content/custom_ner_model /content/drive/MyDrive/